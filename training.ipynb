{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv2D, Flatten\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.merge import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Importing\n"
     ]
    }
   ],
   "source": [
    "print \"Done Importing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arch 1: Normal dense fully-connected neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph to hold the model.\n",
    "graph_dense = tf.Graph()\n",
    "\n",
    "# Create model in the graph.\n",
    "with graph_dense.as_default():\n",
    "\n",
    "    # Keras layers can be called on TensorFlow tensors:\n",
    "    board = tf.placeholder(tf.float32, shape=(None, 42), name='board')\n",
    "    outcome = tf.placeholder(tf.float32, shape=(None, 3), name='outcome')\n",
    "\n",
    "    # Fully connected layers\n",
    "    \n",
    "    x = Dense(2048,\n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l2(0.1),\n",
    "              bias_regularizer=regularizers.l2(0.1),\n",
    "              kernel_initializer='random_uniform',\n",
    "              bias_initializer='zeros')(board)\n",
    "    \n",
    "    x = Dense(1024,\n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l2(0.1),\n",
    "              bias_regularizer=regularizers.l2(0.1),\n",
    "              kernel_initializer='random_uniform',\n",
    "              bias_initializer='zeros')(x)\n",
    "   \n",
    "    x = Dense(512,\n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l2(0.1),\n",
    "              bias_regularizer=regularizers.l2(0.1),\n",
    "              kernel_initializer='random_uniform',\n",
    "              bias_initializer='zeros')(x)\n",
    "    \n",
    "    x = Dense(48,\n",
    "              activation='relu',\n",
    "              kernel_regularizer=regularizers.l2(0.1),\n",
    "              bias_regularizer=regularizers.l2(0.1),\n",
    "              kernel_initializer='random_uniform',\n",
    "              bias_initializer='zeros')(x)\n",
    "\n",
    "    # output layer with 10 units and a softmax activation\n",
    "    preds = Dense(3, activation='softmax', name='preds')(x) \n",
    "        \n",
    "    with tf.name_scope('evaluation') as scope:\n",
    "        \n",
    "        loss = tf.identity(tf.reduce_mean(categorical_crossentropy(outcome, preds)), name='loss')\n",
    "        accuracy = tf.identity(tf.reduce_mean(categorical_accuracy(outcome, preds)), name='accuracy')\n",
    "                                    \n",
    "        holdout_summaries = tf.identity(tf.summary.merge([\n",
    "            tf.summary.scalar('holdout_loss', loss),\n",
    "            tf.summary.scalar('holdout_accuracy', accuracy)]),\n",
    "            name='holdout_summaries')\n",
    "        \n",
    "        batch_summaries = tf.identity(tf.summary.merge([\n",
    "            tf.summary.scalar('batch_loss', loss),\n",
    "            tf.summary.scalar('batch_accuracy', accuracy)]),\n",
    "            name='batch_summaries')       \n",
    "    \n",
    "    with tf.name_scope('training') as scope:\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss, name='train_step')\n",
    "    \n",
    "    # Initialize all variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    #all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = (training.DataLoader(frac_train=0.80, frac_test=0.20)\n",
    "           .add_dataset('gen-1-2017-10-22-133109')\n",
    "           .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ./models/dense_2017_11_04_120354\n",
      "Batch        0 Hold-Out Accuracy: 0.5129 Loss: 2.3747 Time taken: 0.1s\n",
      "Batch     1000 Hold-Out Accuracy: 0.5392 Loss: 0.7456 Time taken: 34.7s\n",
      "Batch     2000 Hold-Out Accuracy: 0.5318 Loss: 0.7183 Time taken: 39.9s\n"
     ]
    }
   ],
   "source": [
    "training.train(graph_dense, './models/dense_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")),\n",
    "               ds_test,  batch_size=100, num_batches=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "board\n",
      "outcome\n",
      "dense_1/random_uniform/shape\n",
      "dense_1/random_uniform/min\n",
      "dense_1/random_uniform/max\n",
      "dense_1/random_uniform/RandomUniform\n",
      "dense_1/random_uniform/sub\n",
      "dense_1/random_uniform/mul\n",
      "dense_1/random_uniform\n",
      "dense_1/kernel\n",
      "dense_1/kernel/Assign\n",
      "dense_1/kernel/read\n",
      "dense_1/Square\n",
      "dense_1/mul/x\n",
      "dense_1/mul\n",
      "dense_1/Const\n",
      "dense_1/Sum\n",
      "dense_1/add/x\n",
      "dense_1/add\n",
      "dense_1/Const_1\n",
      "dense_1/bias\n",
      "dense_1/bias/Assign\n",
      "dense_1/bias/read\n",
      "dense_1/Square_1\n",
      "dense_1/mul_1/x\n",
      "dense_1/mul_1\n",
      "dense_1/Const_2\n",
      "dense_1/Sum_1\n",
      "dense_1/add_1/x\n",
      "dense_1/add_1\n",
      "dense_1/MatMul\n",
      "dense_1/BiasAdd\n",
      "dense_1/Relu\n",
      "dense_2/random_uniform/shape\n",
      "dense_2/random_uniform/min\n",
      "dense_2/random_uniform/max\n",
      "dense_2/random_uniform/RandomUniform\n",
      "dense_2/random_uniform/sub\n",
      "dense_2/random_uniform/mul\n",
      "dense_2/random_uniform\n",
      "dense_2/kernel\n",
      "dense_2/kernel/Assign\n",
      "dense_2/kernel/read\n",
      "dense_2/Square\n",
      "dense_2/mul/x\n",
      "dense_2/mul\n",
      "dense_2/Const\n",
      "dense_2/Sum\n",
      "dense_2/add/x\n",
      "dense_2/add\n",
      "dense_2/Const_1\n",
      "dense_2/bias\n",
      "dense_2/bias/Assign\n",
      "dense_2/bias/read\n",
      "dense_2/Square_1\n",
      "dense_2/mul_1/x\n",
      "dense_2/mul_1\n",
      "dense_2/Const_2\n",
      "dense_2/Sum_1\n",
      "dense_2/add_1/x\n",
      "dense_2/add_1\n",
      "dense_2/MatMul\n",
      "dense_2/BiasAdd\n",
      "dense_2/Relu\n",
      "dense_3/random_uniform/shape\n",
      "dense_3/random_uniform/min\n",
      "dense_3/random_uniform/max\n",
      "dense_3/random_uniform/RandomUniform\n",
      "dense_3/random_uniform/sub\n",
      "dense_3/random_uniform/mul\n",
      "dense_3/random_uniform\n",
      "dense_3/kernel\n",
      "dense_3/kernel/Assign\n",
      "dense_3/kernel/read\n",
      "dense_3/Square\n",
      "dense_3/mul/x\n",
      "dense_3/mul\n",
      "dense_3/Const\n",
      "dense_3/Sum\n",
      "dense_3/add/x\n",
      "dense_3/add\n",
      "dense_3/Const_1\n",
      "dense_3/bias\n",
      "dense_3/bias/Assign\n",
      "dense_3/bias/read\n",
      "dense_3/Square_1\n",
      "dense_3/mul_1/x\n",
      "dense_3/mul_1\n",
      "dense_3/Const_2\n",
      "dense_3/Sum_1\n",
      "dense_3/add_1/x\n",
      "dense_3/add_1\n",
      "dense_3/MatMul\n",
      "dense_3/BiasAdd\n",
      "dense_3/Relu\n",
      "dense_4/random_uniform/shape\n",
      "dense_4/random_uniform/min\n",
      "dense_4/random_uniform/max\n",
      "dense_4/random_uniform/RandomUniform\n",
      "dense_4/random_uniform/sub\n",
      "dense_4/random_uniform/mul\n",
      "dense_4/random_uniform\n",
      "dense_4/kernel\n",
      "dense_4/kernel/Assign\n",
      "dense_4/kernel/read\n",
      "dense_4/Square\n",
      "dense_4/mul/x\n",
      "dense_4/mul\n",
      "dense_4/Const\n",
      "dense_4/Sum\n",
      "dense_4/add/x\n",
      "dense_4/add\n",
      "dense_4/Const_1\n",
      "dense_4/bias\n",
      "dense_4/bias/Assign\n",
      "dense_4/bias/read\n",
      "dense_4/Square_1\n",
      "dense_4/mul_1/x\n",
      "dense_4/mul_1\n",
      "dense_4/Const_2\n",
      "dense_4/Sum_1\n",
      "dense_4/add_1/x\n",
      "dense_4/add_1\n",
      "dense_4/MatMul\n",
      "dense_4/BiasAdd\n",
      "dense_4/Relu\n",
      "preds/random_uniform/shape\n",
      "preds/random_uniform/min\n",
      "preds/random_uniform/max\n",
      "preds/random_uniform/RandomUniform\n",
      "preds/random_uniform/sub\n",
      "preds/random_uniform/mul\n",
      "preds/random_uniform\n",
      "preds/kernel\n",
      "preds/kernel/Assign\n",
      "preds/kernel/read\n",
      "preds/Const\n",
      "preds/bias\n",
      "preds/bias/Assign\n",
      "preds/bias/read\n",
      "preds/MatMul\n",
      "preds/BiasAdd\n",
      "preds/Softmax\n",
      "evaluation/Sum/reduction_indices\n",
      "evaluation/Sum\n",
      "evaluation/div\n",
      "evaluation/Const\n",
      "evaluation/sub/x\n",
      "evaluation/sub\n",
      "evaluation/clip_by_value/Minimum\n",
      "evaluation/clip_by_value\n",
      "evaluation/Log\n",
      "evaluation/mul\n",
      "evaluation/Sum_1/reduction_indices\n",
      "evaluation/Sum_1\n",
      "evaluation/Neg\n",
      "evaluation/Const_1\n",
      "evaluation/Mean\n",
      "evaluation/loss\n",
      "evaluation/ArgMax/dimension\n",
      "evaluation/ArgMax\n",
      "evaluation/ArgMax_1/dimension\n",
      "evaluation/ArgMax_1\n",
      "evaluation/Equal\n",
      "evaluation/Cast\n",
      "evaluation/Const_2\n",
      "evaluation/Mean_1\n",
      "evaluation/accuracy\n",
      "evaluation/holdout_loss/tags\n",
      "evaluation/holdout_loss\n",
      "evaluation/holdout_accuracy/tags\n",
      "evaluation/holdout_accuracy\n",
      "evaluation/Merge/MergeSummary\n",
      "evaluation/holdout_summaries\n",
      "training/gradients/Shape\n",
      "training/gradients/Const\n",
      "training/gradients/Fill\n",
      "training/gradients/evaluation/Mean_grad/Reshape/shape\n",
      "training/gradients/evaluation/Mean_grad/Reshape\n",
      "training/gradients/evaluation/Mean_grad/Shape\n",
      "training/gradients/evaluation/Mean_grad/Tile\n",
      "training/gradients/evaluation/Mean_grad/Shape_1\n",
      "training/gradients/evaluation/Mean_grad/Shape_2\n",
      "training/gradients/evaluation/Mean_grad/Const\n",
      "training/gradients/evaluation/Mean_grad/Prod\n",
      "training/gradients/evaluation/Mean_grad/Const_1\n",
      "training/gradients/evaluation/Mean_grad/Prod_1\n",
      "training/gradients/evaluation/Mean_grad/Maximum/y\n",
      "training/gradients/evaluation/Mean_grad/Maximum\n",
      "training/gradients/evaluation/Mean_grad/floordiv\n",
      "training/gradients/evaluation/Mean_grad/Cast\n",
      "training/gradients/evaluation/Mean_grad/truediv\n",
      "training/gradients/evaluation/Neg_grad/Neg\n",
      "training/gradients/evaluation/Sum_1_grad/Shape\n",
      "training/gradients/evaluation/Sum_1_grad/Size\n",
      "training/gradients/evaluation/Sum_1_grad/add\n",
      "training/gradients/evaluation/Sum_1_grad/mod\n",
      "training/gradients/evaluation/Sum_1_grad/Shape_1\n",
      "training/gradients/evaluation/Sum_1_grad/range/start\n",
      "training/gradients/evaluation/Sum_1_grad/range/delta\n",
      "training/gradients/evaluation/Sum_1_grad/range\n",
      "training/gradients/evaluation/Sum_1_grad/Fill/value\n",
      "training/gradients/evaluation/Sum_1_grad/Fill\n",
      "training/gradients/evaluation/Sum_1_grad/DynamicStitch\n",
      "training/gradients/evaluation/Sum_1_grad/Maximum/y\n",
      "training/gradients/evaluation/Sum_1_grad/Maximum\n",
      "training/gradients/evaluation/Sum_1_grad/floordiv\n",
      "training/gradients/evaluation/Sum_1_grad/Reshape\n",
      "training/gradients/evaluation/Sum_1_grad/Tile\n",
      "training/gradients/evaluation/mul_grad/Shape\n",
      "training/gradients/evaluation/mul_grad/Shape_1\n",
      "training/gradients/evaluation/mul_grad/BroadcastGradientArgs\n",
      "training/gradients/evaluation/mul_grad/mul\n",
      "training/gradients/evaluation/mul_grad/Sum\n",
      "training/gradients/evaluation/mul_grad/Reshape\n",
      "training/gradients/evaluation/mul_grad/mul_1\n",
      "training/gradients/evaluation/mul_grad/Sum_1\n",
      "training/gradients/evaluation/mul_grad/Reshape_1\n",
      "training/gradients/evaluation/mul_grad/tuple/group_deps\n",
      "training/gradients/evaluation/mul_grad/tuple/control_dependency\n",
      "training/gradients/evaluation/mul_grad/tuple/control_dependency_1\n",
      "training/gradients/evaluation/Log_grad/Reciprocal\n",
      "training/gradients/evaluation/Log_grad/mul\n",
      "training/gradients/evaluation/clip_by_value_grad/Shape\n",
      "training/gradients/evaluation/clip_by_value_grad/Shape_1\n",
      "training/gradients/evaluation/clip_by_value_grad/Shape_2\n",
      "training/gradients/evaluation/clip_by_value_grad/zeros/Const\n",
      "training/gradients/evaluation/clip_by_value_grad/zeros\n",
      "training/gradients/evaluation/clip_by_value_grad/GreaterEqual\n",
      "training/gradients/evaluation/clip_by_value_grad/BroadcastGradientArgs\n",
      "training/gradients/evaluation/clip_by_value_grad/Select\n",
      "training/gradients/evaluation/clip_by_value_grad/Select_1\n",
      "training/gradients/evaluation/clip_by_value_grad/Sum\n",
      "training/gradients/evaluation/clip_by_value_grad/Reshape\n",
      "training/gradients/evaluation/clip_by_value_grad/Sum_1\n",
      "training/gradients/evaluation/clip_by_value_grad/Reshape_1\n",
      "training/gradients/evaluation/clip_by_value_grad/tuple/group_deps\n",
      "training/gradients/evaluation/clip_by_value_grad/tuple/control_dependency\n",
      "training/gradients/evaluation/clip_by_value_grad/tuple/control_dependency_1\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Shape\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Shape_1\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Shape_2\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/zeros/Const\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/zeros\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/LessEqual\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/BroadcastGradientArgs\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Select\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Select_1\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Sum\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Reshape\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Sum_1\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/Reshape_1\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/tuple/group_deps\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/tuple/control_dependency\n",
      "training/gradients/evaluation/clip_by_value/Minimum_grad/tuple/control_dependency_1\n",
      "training/gradients/evaluation/div_grad/Shape\n",
      "training/gradients/evaluation/div_grad/Shape_1\n",
      "training/gradients/evaluation/div_grad/BroadcastGradientArgs\n",
      "training/gradients/evaluation/div_grad/RealDiv\n",
      "training/gradients/evaluation/div_grad/Sum\n",
      "training/gradients/evaluation/div_grad/Reshape\n",
      "training/gradients/evaluation/div_grad/Neg\n",
      "training/gradients/evaluation/div_grad/RealDiv_1\n",
      "training/gradients/evaluation/div_grad/RealDiv_2\n",
      "training/gradients/evaluation/div_grad/mul\n",
      "training/gradients/evaluation/div_grad/Sum_1\n",
      "training/gradients/evaluation/div_grad/Reshape_1\n",
      "training/gradients/evaluation/div_grad/tuple/group_deps\n",
      "training/gradients/evaluation/div_grad/tuple/control_dependency\n",
      "training/gradients/evaluation/div_grad/tuple/control_dependency_1\n",
      "training/gradients/evaluation/Sum_grad/Shape\n",
      "training/gradients/evaluation/Sum_grad/Size\n",
      "training/gradients/evaluation/Sum_grad/add\n",
      "training/gradients/evaluation/Sum_grad/mod\n",
      "training/gradients/evaluation/Sum_grad/Shape_1\n",
      "training/gradients/evaluation/Sum_grad/range/start\n",
      "training/gradients/evaluation/Sum_grad/range/delta\n",
      "training/gradients/evaluation/Sum_grad/range\n",
      "training/gradients/evaluation/Sum_grad/Fill/value\n",
      "training/gradients/evaluation/Sum_grad/Fill\n",
      "training/gradients/evaluation/Sum_grad/DynamicStitch\n",
      "training/gradients/evaluation/Sum_grad/Maximum/y\n",
      "training/gradients/evaluation/Sum_grad/Maximum\n",
      "training/gradients/evaluation/Sum_grad/floordiv\n",
      "training/gradients/evaluation/Sum_grad/Reshape\n",
      "training/gradients/evaluation/Sum_grad/Tile\n",
      "training/gradients/AddN\n",
      "training/gradients/preds/Softmax_grad/mul\n",
      "training/gradients/preds/Softmax_grad/Sum/reduction_indices\n",
      "training/gradients/preds/Softmax_grad/Sum\n",
      "training/gradients/preds/Softmax_grad/Reshape/shape\n",
      "training/gradients/preds/Softmax_grad/Reshape\n",
      "training/gradients/preds/Softmax_grad/sub\n",
      "training/gradients/preds/Softmax_grad/mul_1\n",
      "training/gradients/preds/BiasAdd_grad/BiasAddGrad\n",
      "training/gradients/preds/BiasAdd_grad/tuple/group_deps\n",
      "training/gradients/preds/BiasAdd_grad/tuple/control_dependency\n",
      "training/gradients/preds/BiasAdd_grad/tuple/control_dependency_1\n",
      "training/gradients/preds/MatMul_grad/MatMul\n",
      "training/gradients/preds/MatMul_grad/MatMul_1\n",
      "training/gradients/preds/MatMul_grad/tuple/group_deps\n",
      "training/gradients/preds/MatMul_grad/tuple/control_dependency\n",
      "training/gradients/preds/MatMul_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_4/Relu_grad/ReluGrad\n",
      "training/gradients/dense_4/BiasAdd_grad/BiasAddGrad\n",
      "training/gradients/dense_4/BiasAdd_grad/tuple/group_deps\n",
      "training/gradients/dense_4/BiasAdd_grad/tuple/control_dependency\n",
      "training/gradients/dense_4/BiasAdd_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_4/MatMul_grad/MatMul\n",
      "training/gradients/dense_4/MatMul_grad/MatMul_1\n",
      "training/gradients/dense_4/MatMul_grad/tuple/group_deps\n",
      "training/gradients/dense_4/MatMul_grad/tuple/control_dependency\n",
      "training/gradients/dense_4/MatMul_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_3/Relu_grad/ReluGrad\n",
      "training/gradients/dense_3/BiasAdd_grad/BiasAddGrad\n",
      "training/gradients/dense_3/BiasAdd_grad/tuple/group_deps\n",
      "training/gradients/dense_3/BiasAdd_grad/tuple/control_dependency\n",
      "training/gradients/dense_3/BiasAdd_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_3/MatMul_grad/MatMul\n",
      "training/gradients/dense_3/MatMul_grad/MatMul_1\n",
      "training/gradients/dense_3/MatMul_grad/tuple/group_deps\n",
      "training/gradients/dense_3/MatMul_grad/tuple/control_dependency\n",
      "training/gradients/dense_3/MatMul_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_2/Relu_grad/ReluGrad\n",
      "training/gradients/dense_2/BiasAdd_grad/BiasAddGrad\n",
      "training/gradients/dense_2/BiasAdd_grad/tuple/group_deps\n",
      "training/gradients/dense_2/BiasAdd_grad/tuple/control_dependency\n",
      "training/gradients/dense_2/BiasAdd_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_2/MatMul_grad/MatMul\n",
      "training/gradients/dense_2/MatMul_grad/MatMul_1\n",
      "training/gradients/dense_2/MatMul_grad/tuple/group_deps\n",
      "training/gradients/dense_2/MatMul_grad/tuple/control_dependency\n",
      "training/gradients/dense_2/MatMul_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_1/Relu_grad/ReluGrad\n",
      "training/gradients/dense_1/BiasAdd_grad/BiasAddGrad\n",
      "training/gradients/dense_1/BiasAdd_grad/tuple/group_deps\n",
      "training/gradients/dense_1/BiasAdd_grad/tuple/control_dependency\n",
      "training/gradients/dense_1/BiasAdd_grad/tuple/control_dependency_1\n",
      "training/gradients/dense_1/MatMul_grad/MatMul\n",
      "training/gradients/dense_1/MatMul_grad/MatMul_1\n",
      "training/gradients/dense_1/MatMul_grad/tuple/group_deps\n",
      "training/gradients/dense_1/MatMul_grad/tuple/control_dependency\n",
      "training/gradients/dense_1/MatMul_grad/tuple/control_dependency_1\n",
      "training/beta1_power/initial_value\n",
      "training/beta1_power\n",
      "training/beta1_power/Assign\n",
      "training/beta1_power/read\n",
      "training/beta2_power/initial_value\n",
      "training/beta2_power\n",
      "training/beta2_power/Assign\n",
      "training/beta2_power/read\n",
      "dense_1/kernel/Adam/Initializer/zeros\n",
      "dense_1/kernel/Adam\n",
      "dense_1/kernel/Adam/Assign\n",
      "dense_1/kernel/Adam/read\n",
      "dense_1/kernel/Adam_1/Initializer/zeros\n",
      "dense_1/kernel/Adam_1\n",
      "dense_1/kernel/Adam_1/Assign\n",
      "dense_1/kernel/Adam_1/read\n",
      "dense_1/bias/Adam/Initializer/zeros\n",
      "dense_1/bias/Adam\n",
      "dense_1/bias/Adam/Assign\n",
      "dense_1/bias/Adam/read\n",
      "dense_1/bias/Adam_1/Initializer/zeros\n",
      "dense_1/bias/Adam_1\n",
      "dense_1/bias/Adam_1/Assign\n",
      "dense_1/bias/Adam_1/read\n",
      "dense_2/kernel/Adam/Initializer/zeros\n",
      "dense_2/kernel/Adam\n",
      "dense_2/kernel/Adam/Assign\n",
      "dense_2/kernel/Adam/read\n",
      "dense_2/kernel/Adam_1/Initializer/zeros\n",
      "dense_2/kernel/Adam_1\n",
      "dense_2/kernel/Adam_1/Assign\n",
      "dense_2/kernel/Adam_1/read\n",
      "dense_2/bias/Adam/Initializer/zeros\n",
      "dense_2/bias/Adam\n",
      "dense_2/bias/Adam/Assign\n",
      "dense_2/bias/Adam/read\n",
      "dense_2/bias/Adam_1/Initializer/zeros\n",
      "dense_2/bias/Adam_1\n",
      "dense_2/bias/Adam_1/Assign\n",
      "dense_2/bias/Adam_1/read\n",
      "dense_3/kernel/Adam/Initializer/zeros\n",
      "dense_3/kernel/Adam\n",
      "dense_3/kernel/Adam/Assign\n",
      "dense_3/kernel/Adam/read\n",
      "dense_3/kernel/Adam_1/Initializer/zeros\n",
      "dense_3/kernel/Adam_1\n",
      "dense_3/kernel/Adam_1/Assign\n",
      "dense_3/kernel/Adam_1/read\n",
      "dense_3/bias/Adam/Initializer/zeros\n",
      "dense_3/bias/Adam\n",
      "dense_3/bias/Adam/Assign\n",
      "dense_3/bias/Adam/read\n",
      "dense_3/bias/Adam_1/Initializer/zeros\n",
      "dense_3/bias/Adam_1\n",
      "dense_3/bias/Adam_1/Assign\n",
      "dense_3/bias/Adam_1/read\n",
      "dense_4/kernel/Adam/Initializer/zeros\n",
      "dense_4/kernel/Adam\n",
      "dense_4/kernel/Adam/Assign\n",
      "dense_4/kernel/Adam/read\n",
      "dense_4/kernel/Adam_1/Initializer/zeros\n",
      "dense_4/kernel/Adam_1\n",
      "dense_4/kernel/Adam_1/Assign\n",
      "dense_4/kernel/Adam_1/read\n",
      "dense_4/bias/Adam/Initializer/zeros\n",
      "dense_4/bias/Adam\n",
      "dense_4/bias/Adam/Assign\n",
      "dense_4/bias/Adam/read\n",
      "dense_4/bias/Adam_1/Initializer/zeros\n",
      "dense_4/bias/Adam_1\n",
      "dense_4/bias/Adam_1/Assign\n",
      "dense_4/bias/Adam_1/read\n",
      "preds/kernel/Adam/Initializer/zeros\n",
      "preds/kernel/Adam\n",
      "preds/kernel/Adam/Assign\n",
      "preds/kernel/Adam/read\n",
      "preds/kernel/Adam_1/Initializer/zeros\n",
      "preds/kernel/Adam_1\n",
      "preds/kernel/Adam_1/Assign\n",
      "preds/kernel/Adam_1/read\n",
      "preds/bias/Adam/Initializer/zeros\n",
      "preds/bias/Adam\n",
      "preds/bias/Adam/Assign\n",
      "preds/bias/Adam/read\n",
      "preds/bias/Adam_1/Initializer/zeros\n",
      "preds/bias/Adam_1\n",
      "preds/bias/Adam_1/Assign\n",
      "preds/bias/Adam_1/read\n",
      "training/train_step/learning_rate\n",
      "training/train_step/beta1\n",
      "training/train_step/beta2\n",
      "training/train_step/epsilon\n",
      "training/train_step/update_dense_1/kernel/ApplyAdam\n",
      "training/train_step/update_dense_1/bias/ApplyAdam\n",
      "training/train_step/update_dense_2/kernel/ApplyAdam\n",
      "training/train_step/update_dense_2/bias/ApplyAdam\n",
      "training/train_step/update_dense_3/kernel/ApplyAdam\n",
      "training/train_step/update_dense_3/bias/ApplyAdam\n",
      "training/train_step/update_dense_4/kernel/ApplyAdam\n",
      "training/train_step/update_dense_4/bias/ApplyAdam\n",
      "training/train_step/update_preds/kernel/ApplyAdam\n",
      "training/train_step/update_preds/bias/ApplyAdam\n",
      "training/train_step/mul\n",
      "training/train_step/Assign\n",
      "training/train_step/mul_1\n",
      "training/train_step/Assign_1\n",
      "training/train_step\n",
      "init\n"
     ]
    }
   ],
   "source": [
    "for i in graph_dense.get_operations():\n",
    "    print i.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001e",
      "\n",
      "\u0017evaluation/holdout_loss\u0015�̌? \n",
      "\u001e",
      "\n",
      "\u0017evaluation/holdout_loss\u0015�̌?\n",
      "\"\n",
      "\u001bevaluation/holdout_accuracy\u0015��>\n"
     ]
    }
   ],
   "source": [
    "#holdout_summaries = [\n",
    "#        graph_dense.get_tensor_by_name('evaluation/holdout_loss:0'),\n",
    "#        graph_dense.get_tensor_by_name('evaluation/holdout_accuracy:0')\n",
    "#    ]\n",
    "\n",
    "hol = graph_dense.get_tensor_by_name('evaluation/holdout_loss:0')\n",
    "sums = graph_dense.get_tensor_by_name('evaluation/holdout_summaries:0')\n",
    "\n",
    "\n",
    "#sums = graph_dense.get_operation_by_name('evaluation/Merge/MergeSummary')\n",
    "#batch_summaries = [\n",
    "#        graph_dense.get_operation_by_name('evaluation/batch_loss'),\n",
    "#        graph_dense.get_operation_by_name('evaluation/batch_accuracy')\n",
    "#    ]\n",
    "\n",
    "with tf.Session(graph=graph_dense) as sess:\n",
    "    K.set_session(sess)\n",
    "    sess.run(init_op)\n",
    "        \n",
    "    x, y = sess.run([hol, sums], feed_dict={board: ds_test.X_test, outcome: ds_test.y_test})\n",
    "    #z = graph_dense.get_operation_by_name('evaluation/holdout_loss').run(feed_dict={board: ds_test.X_test, outcome: ds_test.y_test})\n",
    "    \n",
    "    print x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arch 2: Pure CovNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a graph to hold the model.\n",
    "graph_cov_pure = tf.Graph()\n",
    "\n",
    "# Create model in the graph.\n",
    "with graph_cov_pure.as_default():\n",
    "    \n",
    "    # Keras layers can be called on TensorFlow tensors:\n",
    "    board = tf.placeholder(tf.float32, shape=(None, 42), name='board') \n",
    "    outcome = tf.placeholder(tf.float32, shape=(None, 3), name='outcome')    \n",
    "    \n",
    "    # The input data is [col0=[row_0, row_1, ...], col1=[row_0, row_1], ...]\n",
    "    rs = Reshape((7, 6, 1), input_shape=(42,))(board)\n",
    "    \n",
    "    conv_args = dict(\n",
    "        use_bias=True,\n",
    "        activation='relu',\n",
    "        kernel_initializer='random_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        kernel_regularizer=regularizers.l2(0.01),\n",
    "        input_shape=(7, 6, 1),\n",
    "        padding='valid'\n",
    "    )\n",
    "    \n",
    "    # We use a few parallel covents, that we combine in the end        \n",
    "    c1 = (Conv2D(8,  kernel_size=(1, 2), **conv_args)(rs))\n",
    "    c2 = (Conv2D(16, kernel_size=(2, 1), **conv_args)(c1))\n",
    "    c3 = (Conv2D(32, kernel_size=(3, 3), **conv_args)(c2))\n",
    "    #c4 = (Conv2D(64, kernel_size=(6, 6), **conv_args)(c3))\n",
    "    \n",
    "    dense_args = dict(\n",
    "        use_bias=True,\n",
    "        activation='relu',\n",
    "        kernel_initializer='random_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        kernel_regularizer=regularizers.l2(0.01),\n",
    "        bias_regularizer=regularizers.l2(0.01),    \n",
    "    )\n",
    "    \n",
    "    d = Dense(64,  **dense_args)(Flatten()(c3))         \n",
    "    \n",
    "    # output layer with 10 units and a softmax activation\n",
    "    preds = Dense(3, activation='softmax', name='preds')(d) \n",
    "    \n",
    "    with tf.name_scope('evaluation') as scope:\n",
    "        loss = tf.reduce_mean(categorical_crossentropy(outcome, preds), name='loss')\n",
    "        tf.summary.scalar('holdout_loss', loss)\n",
    "        \n",
    "        acc_value = tf.identity(accuracy(outcome, preds), name='accuracy')\n",
    "        tf.summary.scalar('holdout_accuracy', tf.reduce_mean(acc_value))\n",
    "    \n",
    "    with tf.name_scope('training') as scope:\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss, name='train_step')    \n",
    "    \n",
    "    # Initialize all variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arch 3: Complicated CovNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph to hold the model.\n",
    "graph_cov_comp = tf.Graph()\n",
    "\n",
    "# Create model in the graph.\n",
    "with graph_cov_comp.as_default():\n",
    "    \n",
    "    # Keras layers can be called on TensorFlow tensors:\n",
    "    board = tf.placeholder(tf.float32, shape=(None, 42), name='board') \n",
    "    outcome = tf.placeholder(tf.float32, shape=(None, 3), name='outcome')    \n",
    "    \n",
    "    # The input data is [col0=[row_0, row_1, ...], col1=[row_0, row_1], ...]\n",
    "    rs = Reshape((7, 6, 1), input_shape=(42,))(board)\n",
    "    \n",
    "    conv_args = dict(\n",
    "        use_bias=True,\n",
    "        activation='relu',\n",
    "        kernel_initializer='random_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        kernel_regularizer=regularizers.l1_l2(1.0),\n",
    "        bias_regularizer=regularizers.l1_l2(1.0),\n",
    "#        input_shape=(7, 6, 1),\n",
    "        padding='valid'\n",
    "    )\n",
    "    \n",
    "    # We use a few parallel covents, that we combine in the end        \n",
    "    ca = Flatten()(Conv2D(12, kernel_size=(5, 5), **conv_args)(rs))\n",
    "    cb = Flatten()(Conv2D(12, kernel_size=(4, 4), **conv_args)(rs))\n",
    "    cc = Flatten()(Conv2D(12, kernel_size=(3, 3), **conv_args)(rs))\n",
    "\n",
    "    cg = Flatten()(Conv2D(8, kernel_size=(6, 1), **conv_args)(rs))\n",
    "    ch = Flatten()(Conv2D(8, kernel_size=(1, 6), **conv_args)(rs))\n",
    "    \n",
    "    cd = Flatten()(Conv2D(4, kernel_size=(1, 4), **conv_args)(rs))\n",
    "    ce = Flatten()(Conv2D(4, kernel_size=(4, 1), **conv_args)(rs))\n",
    "    cf = Flatten()(Conv2D(4, kernel_size=(2, 2), **conv_args)(rs))\n",
    "\n",
    "    dense_args = dict(\n",
    "        use_bias=True,\n",
    "        activation='relu',\n",
    "        kernel_initializer='random_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        kernel_regularizer=regularizers.l1_l2(1.0),\n",
    "        bias_regularizer=regularizers.l1_l2(1.0),    \n",
    "    )\n",
    "    \n",
    "    d1 = Dense(512, **dense_args)(board)\n",
    "    \n",
    "    merged = Concatenate()([d1, ca, cb, cc, cd, ce, cf, cg, ch])    \n",
    "        \n",
    "    x = Dense(512, **dense_args)(merged)         \n",
    "    x = Dense(256, **dense_args)(x)         \n",
    "    x = Dense(128, **dense_args)(x)    \n",
    "    x = Dense(12,  **dense_args)(x)\n",
    "    \n",
    "    # output layer with 10 units and a softmax activation\n",
    "    preds = Dense(3, activation='softmax', name='preds')(x) \n",
    "    \n",
    "    with tf.name_scope('evaluation') as scope:\n",
    "        loss = tf.reduce_mean(categorical_crossentropy(outcome, preds), name='loss')\n",
    "        tf.summary.scalar('holdout_loss', loss)\n",
    "        \n",
    "        acc = tf.identity(accuracy(outcome, preds), name='accuracy')\n",
    "        tf.summary.scalar('holdout_accuracy', tf.reduce_mean(acc))\n",
    "    \n",
    "    with tf.name_scope('training') as scope:\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss, name='train_step')    \n",
    "    \n",
    "    # Initialize all variables\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulations/random-2017-10-28-17:13:04\n",
    "\n",
    "# 'random-2017-10-21-13:41:47'\n",
    "# 'random-2017-10-28-17:13:04'\n",
    "\n",
    "ds_gen1 = (training.DataLoader(frac_train=0.95, frac_test=0.05)\n",
    "           .add_dataset('random-2017-10-28-17:13:04')\n",
    "           .load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training.train(graph_dense, './models/dense_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")),\n",
    "               ds_gen1,  batch_size=500, num_batches=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.train(graph_cov_pure, './models/cov_pure_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")),\n",
    "               ds_gen1,  batch_size=200, num_batches=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Advanced Covnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best: gen1-cov2d_beta_2017_10_29_150829\n",
    "# Dataset: 'random-2017-10-28-17:13:04'\n",
    "# batch_size=500, learning_rate=0.001, regularization=(l1_l2, 1.0) (regularization of 0.1 seems to have the same effect...)\n",
    "# Include all convolutions (adding cc, cf, cg, ch)\n",
    "# Include 4 layers of dense: 512, 256, 128, 12\n",
    "\n",
    "training.train(graph_cov_comp, './models/gen1-cov2d_alpha_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")),\n",
    "               ds_gen1, batch_size=500, num_batches=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gen2 = (training.DataLoader(frac_train=0.95, frac_test=0.05)\n",
    "           .add_dataset('random-2017-10-28-17:13:04', 100000)\n",
    "           .add_dataset('gen1-cov2d_beta_2017_10_29_150829-2017-10-29-16:57:41')\n",
    "           .load())\n",
    "\n",
    "# Use all the advanced data\n",
    "# 10,000 rows of gen-1 vs gen-1 data\n",
    "#key = 'gen-1-cov2d_beta_2017_10_22_142925'\n",
    "#features, targets, features_train, target_train, features_test, target_test = load_data('training_data/gen-1-cov2d_beta_2017_10_22_142925')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.train(graph_cov_comp, './models/gen2-cov2d_beta_{}'.format(datetime.datetime.now().strftime(\"%Y_%m_%d_%H%M%S\")),\n",
    "               ds_gen2, batch_size=250, num_batches=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
